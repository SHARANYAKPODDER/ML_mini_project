{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Author\n",
        "\n",
        "**Student Name**:  SHARANYAK PODDER\n",
        "\n",
        "**Student ID**:  230356331"
      ],
      "metadata": {
        "id": "gyrFLfDfCdLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem formulation\n",
        "\n",
        "Home vs. Restaurant Food Classification:\n",
        "   - Problem: Classifying food items prepared  at home or in a restaurant.\n",
        "   - Model: Binary classification model\n"
      ],
      "metadata": {
        "id": "923HPuyB-d-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step_1: Importing Libraries**"
      ],
      "metadata": {
        "id": "nAkMhi0c-60X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "G4Njbi2z8uDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step_2:** We install the MLEnd Dataset using pip install function and installing some basic python libraries so that colab can access it."
      ],
      "metadata": {
        "id": "LCKH5Vhk_Fvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZOR0Z137MOL",
        "outputId": "efd2cad6-5e49-4733-f9d2-2895edd72084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlend\n",
            "  Downloading mlend-1.0.0.3-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy>1.8 in /usr/local/lib/python3.10/dist-packages (from mlend) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mlend) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlend) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mlend) (3.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from mlend) (1.3.2)\n",
            "Collecting spkit>0.0.9.5 (from mlend)\n",
            "  Downloading spkit-0.0.9.6.7-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (1.2.2)\n",
            "Collecting python-picard (from spkit>0.0.9.5->mlend)\n",
            "  Downloading python_picard-0.7-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (1.5.0)\n",
            "Collecting pylfsr (from spkit>0.0.9.5->mlend)\n",
            "  Downloading pylfsr-1.0.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (3.9.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (0.12.2)\n",
            "Collecting phyaat (from spkit>0.0.9.5->mlend)\n",
            "  Downloading phyaat-0.0.3-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mlend) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mlend) (1.16.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from python-picard->spkit>0.0.9.5->mlend) (2.8.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->spkit>0.0.9.5->mlend) (3.2.0)\n",
            "Installing collected packages: python-picard, pylfsr, phyaat, spkit, mlend\n",
            "Successfully installed mlend-1.0.0.3 phyaat-0.0.3 pylfsr-1.0.7 python-picard-0.7 spkit-0.0.9.6.7\n"
          ]
        }
      ],
      "source": [
        "!pip install mlend"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spkit as sp\n",
        "\n",
        "from skimage import exposure\n",
        "from skimage.color import rgb2hsv, rgb2gray\n",
        "import skimage as ski\n",
        "\n",
        "import mlend\n",
        "from mlend import download_yummy\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK8s_mC07S8h",
        "outputId": "3b5f2312-8dbc-4f3f-cd19-6938985aef40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step_3: Download Data**\n",
        "\n",
        "Here we will download the complete MLEnd Yummy Dataset, i.e. the MLEnd Yummy Dataset. This dataset consists of a total of 3250 samples from the MLEnd Yummy Dataset corresponding to dishes that contain either rice or chips."
      ],
      "metadata": {
        "id": "JdpRb9fy_go5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseDir = download_yummy(save_to = '/content/drive/MyDrive/Data/MLEnd')\n",
        "baseDir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "rOFJRv9k76fE",
        "outputId": "bf0c25db-83cf-4ae9-8aec-4afca8b713ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 3250 image files from https://github.com/MLEndDatasets/Yummy\n",
            "100%|\u001b[0m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[0m|3250\\3250|003250.jpg\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Data/MLEnd/yummy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(baseDir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36RpaLpf8A1p",
        "outputId": "d337fb8e-5dfb-456c-9889-37445a680b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MLEndYD_images_small',\n",
              " 'MLEndYD_image_attributes_small.csv',\n",
              " 'MLEndYD_images',\n",
              " 'MLEndYD_image_attributes_benchmark.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step_4: Understanding Our Dataset**\n",
        "\n",
        "Each sample in the MLEnd Small Yummy Dataset corresponds to one dish instance and is described by 9 attributes, namely:\n",
        "\n",
        "Photo of the dish.\n",
        "\n",
        "Dish name.\n",
        "\n",
        "Whether home or restaurant.\n",
        "\n",
        "Cuisine.\n",
        "\n",
        "Ingredients.\n",
        "\n",
        "Diet.\n",
        "\n",
        "Healthiness rating.\n",
        "\n",
        "Tastiness rating.\n",
        "\n",
        "Rice or chips?\n",
        "\n",
        "The CSV file MLEndYD_image_attributes.csv captures the values of all the attributes of each sample. However, instead of an actual photo, this CSV file stores the name of the photo, e.g. '00001.jpg', that is stored in the separate folder MLEndYD_images."
      ],
      "metadata": {
        "id": "cTeSeNfQ_o3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLENDYD_df = pd.read_csv('/content/drive/MyDrive/Data/MLEnd/yummy/MLEndYD_image_attributes_benchmark.csv').set_index('filename')\n",
        "MLENDYD_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "iJbOTk2S8Da9",
        "outputId": "e56afa7b-8c2f-4a01-a7d2-fda003dfb728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Diet Cuisine_org   Cuisine  \\\n",
              "filename                                           \n",
              "000001.jpg  non_vegetarian    japanese  japanese   \n",
              "000002.jpg  non_vegetarian     english   english   \n",
              "000003.jpg  non_vegetarian     chinese   chinese   \n",
              "000004.jpg      vegetarian      indian    indian   \n",
              "000005.jpg  non_vegetarian      indian    indian   \n",
              "...                    ...         ...       ...   \n",
              "003246.jpg      vegetarian      indian    indian   \n",
              "003247.jpg      vegetarian      indian    indian   \n",
              "003248.jpg      vegetarian      indian    indian   \n",
              "003249.jpg           vegan      indian    indian   \n",
              "003250.jpg  non_vegetarian    american  american   \n",
              "\n",
              "                                   Dish_name     Home_or_restaurant  \\\n",
              "filename                                                              \n",
              "000001.jpg                chicken_katsu_rice          marugame_udon   \n",
              "000002.jpg                 english_breakfast                   home   \n",
              "000003.jpg                     spicy_chicken  jinli_flagship_branch   \n",
              "000004.jpg                       gulab_jamun                   home   \n",
              "000005.jpg                    chicken_masala                   home   \n",
              "...                                      ...                    ...   \n",
              "003246.jpg                        zeera_rice                   home   \n",
              "003247.jpg                    paneer_and_dal                   home   \n",
              "003248.jpg                            samosa                   home   \n",
              "003249.jpg                        fruit_milk                   home   \n",
              "003250.jpg  beef_burger_with_onion_and_salad                   home   \n",
              "\n",
              "                                                  Ingredients  \\\n",
              "filename                                                        \n",
              "000001.jpg              rice,chicken_breast,spicy_curry_sauce   \n",
              "000002.jpg  eggs,bacon,hash_brown,tomato,bread,tomato,bake...   \n",
              "000003.jpg  chili,chicken,peanuts,sihuan_peppercorns,green...   \n",
              "000004.jpg      sugar,water,khoya,milk,salt,oil,cardamon,ghee   \n",
              "000005.jpg  chicken,lemon,turmeric,garam_masala,coriander_...   \n",
              "...                                                       ...   \n",
              "003246.jpg  1_cup_basmati_rice,2_cups_water,2_tablespoons_...   \n",
              "003247.jpg  fried_cottage_cheese,ghee,lentils,milk,wheat_f...   \n",
              "003248.jpg  potato,onion,peanut,salt,turmeric_powder,red_c...   \n",
              "003249.jpg                             kiwi,banana,apple,milk   \n",
              "003250.jpg   beef_patty,bread_roll,cherry_tomato,_onion,chive   \n",
              "\n",
              "           Healthiness_rating  Healthiness_rating_int       Likeness  \\\n",
              "filename                                                               \n",
              "000001.jpg            neutral                     3.0           like   \n",
              "000002.jpg          unhealthy                     2.0           like   \n",
              "000003.jpg            neutral                     3.0  strongly_like   \n",
              "000004.jpg          unhealthy                     2.0  strongly_like   \n",
              "000005.jpg            healthy                     4.0  strongly_like   \n",
              "...                       ...                     ...            ...   \n",
              "003246.jpg            healthy                     4.0  strongly_like   \n",
              "003247.jpg            healthy                     4.0  strongly_like   \n",
              "003248.jpg     very_unhealthy                     1.0           like   \n",
              "003249.jpg       very_healthy                     5.0  strongly_like   \n",
              "003250.jpg            neutral                     3.0           like   \n",
              "\n",
              "            Likeness_int Benchmark_A  \n",
              "filename                              \n",
              "000001.jpg           4.0       Train  \n",
              "000002.jpg           4.0       Train  \n",
              "000003.jpg           5.0       Train  \n",
              "000004.jpg           5.0       Train  \n",
              "000005.jpg           5.0       Train  \n",
              "...                  ...         ...  \n",
              "003246.jpg           5.0       Train  \n",
              "003247.jpg           5.0        Test  \n",
              "003248.jpg           4.0        Test  \n",
              "003249.jpg           5.0       Train  \n",
              "003250.jpg           4.0       Train  \n",
              "\n",
              "[3250 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39656c6a-a751-4ab0-9abd-179ed76e06d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diet</th>\n",
              "      <th>Cuisine_org</th>\n",
              "      <th>Cuisine</th>\n",
              "      <th>Dish_name</th>\n",
              "      <th>Home_or_restaurant</th>\n",
              "      <th>Ingredients</th>\n",
              "      <th>Healthiness_rating</th>\n",
              "      <th>Healthiness_rating_int</th>\n",
              "      <th>Likeness</th>\n",
              "      <th>Likeness_int</th>\n",
              "      <th>Benchmark_A</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000001.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>japanese</td>\n",
              "      <td>japanese</td>\n",
              "      <td>chicken_katsu_rice</td>\n",
              "      <td>marugame_udon</td>\n",
              "      <td>rice,chicken_breast,spicy_curry_sauce</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000002.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>english</td>\n",
              "      <td>english</td>\n",
              "      <td>english_breakfast</td>\n",
              "      <td>home</td>\n",
              "      <td>eggs,bacon,hash_brown,tomato,bread,tomato,bake...</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>2.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000003.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>chinese</td>\n",
              "      <td>chinese</td>\n",
              "      <td>spicy_chicken</td>\n",
              "      <td>jinli_flagship_branch</td>\n",
              "      <td>chili,chicken,peanuts,sihuan_peppercorns,green...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000004.jpg</th>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>gulab_jamun</td>\n",
              "      <td>home</td>\n",
              "      <td>sugar,water,khoya,milk,salt,oil,cardamon,ghee</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>2.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000005.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>chicken_masala</td>\n",
              "      <td>home</td>\n",
              "      <td>chicken,lemon,turmeric,garam_masala,coriander_...</td>\n",
              "      <td>healthy</td>\n",
              "      <td>4.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003246.jpg</th>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>zeera_rice</td>\n",
              "      <td>home</td>\n",
              "      <td>1_cup_basmati_rice,2_cups_water,2_tablespoons_...</td>\n",
              "      <td>healthy</td>\n",
              "      <td>4.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003247.jpg</th>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>paneer_and_dal</td>\n",
              "      <td>home</td>\n",
              "      <td>fried_cottage_cheese,ghee,lentils,milk,wheat_f...</td>\n",
              "      <td>healthy</td>\n",
              "      <td>4.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003248.jpg</th>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>samosa</td>\n",
              "      <td>home</td>\n",
              "      <td>potato,onion,peanut,salt,turmeric_powder,red_c...</td>\n",
              "      <td>very_unhealthy</td>\n",
              "      <td>1.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003249.jpg</th>\n",
              "      <td>vegan</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>fruit_milk</td>\n",
              "      <td>home</td>\n",
              "      <td>kiwi,banana,apple,milk</td>\n",
              "      <td>very_healthy</td>\n",
              "      <td>5.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003250.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>american</td>\n",
              "      <td>american</td>\n",
              "      <td>beef_burger_with_onion_and_salad</td>\n",
              "      <td>home</td>\n",
              "      <td>beef_patty,bread_roll,cherry_tomato,_onion,chive</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3250 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39656c6a-a751-4ab0-9abd-179ed76e06d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39656c6a-a751-4ab0-9abd-179ed76e06d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39656c6a-a751-4ab0-9abd-179ed76e06d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa6b49bc-ab6d-4378-8895-0f88ff8a77a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa6b49bc-ab6d-4378-8895-0f88ff8a77a1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa6b49bc-ab6d-4378-8895-0f88ff8a77a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_path = '/content/drive/MyDrive/Data/MLEnd/yummy/MLEndYD_images/*.jpg'\n",
        "files = glob.glob(sample_path)\n",
        "len(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yabO8uEP8Ieh",
        "outputId": "9c119b9f-5890-419e-beb9-db588d4a23cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3250"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step_5: Splitting the dataset into Traning and Test Datsets**"
      ],
      "metadata": {
        "id": "6bit4Qsq_u8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(MLENDYD_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Mg7zXTUo8MVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning pipeline\n",
        "\n",
        "Constructs a machine learning pipeline using scikit-learn's Pipeline class.\n",
        "The pipeline consists of two stages:\n",
        "\n",
        "1. 'tfidf': Uses TfidfVectorizer to convert the textual descriptions into numerical features using the TF-IDF (Term Frequency-Inverse Document Frequency) representation. It limits the features to 5000 and removes English stop words.\n",
        "\n",
        "2. 'classifier': Employs a logistic regression classifier (LogisticRegression) to predict the 'preparation_location' based on the TF-IDF features."
      ],
      "metadata": {
        "id": "l41-s4m9DLbG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step_6: Building the Machine Learning Pipeline**\n",
        "\n",
        "The pipeline used includes text vectorization using TF-IDF and a logistic regression classifier. It allows us to adjust hyperparameters and try different algorithms based on our dataset and requirements."
      ],
      "metadata": {
        "id": "U9Mzz3R7A5ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "pipeline.fit(train_data['Dish_name'], train_data['Home_or_restaurant'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "f_Ov43ic8yhe",
        "outputId": "321ec319-f880-4147-8965-2e48775aabab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 TfidfVectorizer(max_features=5000, stop_words='english')),\n",
              "                ('classifier', LogisticRegression())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(max_features=5000, stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(max_features=5000, stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=5000, stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation stage\n",
        "\n",
        "We use 'tfidf' which is a user-assigned name for the transformation stage, and TfidfVectorizer is the class responsible for the transformation. TF-IDF stands for Term Frequency-Inverse Document Frequency, a numerical statistic that reflects the importance of a word in a document relative to a collection of documents (corpus).\n",
        "\n",
        "TfidfVectorizer Parameters:\n",
        "max_features: Specifies the maximum number of features (unique words or terms) to be considered. In this case, we are setting it to 5000.\n",
        "\n",
        "stop_words: Specifies that English stop words (common words like \"the,\" \"and,\" etc.)"
      ],
      "metadata": {
        "id": "QRLKjViaEaTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling\n",
        "\n",
        "The two models we used for solving the the problem that wether a dish has been prepared at home or at restaurant are as follows:\n",
        "\n",
        "**1. TF-IDF Vectorizer:**\n",
        "\n",
        "The TF-IDF vectorizer is a crucial component of the pipeline. It transforms the raw text data (food descriptions) into numerical features using the TF-IDF algorithm.\n",
        "\n",
        "**2. Logistic Regression Classifier:**\n",
        "\n",
        "The logistic regression model is employed for the actual classification task. It predicts whether a food item is prepared at home or in a restaurant based on the features generated by the TF-IDF vectorizer."
      ],
      "metadata": {
        "id": "L7n9t8j3FUms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step_7: Making Predictions and Evaluating the model**\n",
        "\n",
        "Here, we provide Dish_name as a test data to out ML pipeline and on the basis of that our model evaluates the accuracy and produces a classification report."
      ],
      "metadata": {
        "id": "CcLk7CWMBgaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pipeline.predict(test_data['Dish_name'])\n",
        "\n",
        "accuracy = accuracy_score(test_data['Home_or_restaurant'], predictions)\n",
        "report = classification_report(test_data['Home_or_restaurant'], predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('\\nClassification Report:\\n', report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ndSHzi9eLm",
        "outputId": "8b2f1d19-5f48-485e-c3ea-040ec9a2dd12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6846153846153846\n",
            "\n",
            "Classification Report:\n",
            "                                  precision    recall  f1-score   support\n",
            "\n",
            "                 36_street_food       0.00      0.00      0.00         1\n",
            "         albura_kathisma_bistro       0.00      0.00      0.00         1\n",
            "            anjappar_restaurant       0.00      0.00      0.00         1\n",
            "                           asda       0.00      0.00      0.00         2\n",
            "                 buns_&_berries       0.00      0.00      0.00         1\n",
            "              burgitzza_watford       0.00      0.00      0.00         1\n",
            "                   chicken_shop       0.00      0.00      0.00         2\n",
            "                   coco_di_mama       0.00      0.00      0.00         1\n",
            "                 dartmoor_lodge       0.00      0.00      0.00         1\n",
            "                  delamina_east       0.00      0.00      0.00         2\n",
            "                      eat_tokyo       0.00      0.00      0.00         1\n",
            "                efes_restaurant       0.00      0.00      0.00         1\n",
            "                       farmer.j       0.00      0.00      0.00         1\n",
            "            fortitude_bakehouse       0.00      0.00      0.00         1\n",
            "                fried_&_grilled       0.00      0.00      0.00         1\n",
            "     german_doner_kebab_watford       0.00      0.00      0.00         1\n",
            "                   green_pepper       0.00      0.00      0.00         1\n",
            "         haidilao_hotpot_london       0.00      0.00      0.00         1\n",
            "                     haldiram’s       0.00      0.00      0.00         1\n",
            "                      half_moon       0.00      0.00      0.00         1\n",
            "harper's_steakhouse_weighbridge       0.00      0.00      0.00         3\n",
            "                 hiba_restraunt       0.00      0.00      0.00         1\n",
            "                           home       0.69      1.00      0.81       446\n",
            "                       homemade       0.00      0.00      0.00         4\n",
            "              homies_on_donkies       0.00      0.00      0.00         1\n",
            "           hong_kong_restaurant       0.00      0.00      0.00         1\n",
            "                joe_&_the_juice       0.00      0.00      0.00         1\n",
            "              jrc_global_buffet       0.00      0.00      0.00         1\n",
            "                            kfc       0.00      0.00      0.00         3\n",
            "                            khf       0.00      0.00      0.00         1\n",
            "                   khyber_grill       0.00      0.00      0.00         3\n",
            "                           leon       0.00      0.00      0.00         1\n",
            "   m&s_food_hall_euston_station       0.00      0.00      0.00         1\n",
            "                  marugame_udon       0.00      0.00      0.00         1\n",
            "                     mc_donalds       0.00      0.00      0.00         1\n",
            "                       mcdonald       0.00      0.00      0.00         1\n",
            "                     mcdonald's       0.00      0.00      0.00         1\n",
            "                      mcdonalds       0.00      0.00      0.00         1\n",
            "                           mian       0.00      0.00      0.00         1\n",
            "          mr_wong’s_wok_&_box_️       0.00      0.00      0.00         1\n",
            "     mrs_chew's_chinese_kitchen       0.00      0.00      0.00         1\n",
            "                   my_old_place       0.00      0.00      0.00         1\n",
            "                        nando's       0.00      0.00      0.00         1\n",
            "         nando's_euston_station       0.00      0.00      0.00         1\n",
            "                         nandos       0.00      0.00      0.00         1\n",
            "                    oowee_diner       0.00      0.00      0.00         1\n",
            "             papa_nadox_kitchen       0.00      0.00      0.00         1\n",
            "                         pilpel       0.00      0.00      0.00         1\n",
            "                      pizza_hut       0.00      0.00      0.00         1\n",
            "                 protein_pizzas       0.00      0.00      0.00         1\n",
            "          qmul_catering_service       0.00      0.00      0.00         1\n",
            "     ramen_babaichiya_tomonojin       0.00      0.00      0.00         1\n",
            "                     resraurant       0.00      0.00      0.00         3\n",
            "                     restaurant       0.25      0.01      0.02       110\n",
            "                    restraurant       0.00      0.00      0.00         1\n",
            "                      resturant       0.00      0.00      0.00         1\n",
            "                     resturaunt       0.00      0.00      0.00         1\n",
            "               rosa's_thai_café       0.00      0.00      0.00         1\n",
            "                    sainsbury's       0.00      0.00      0.00         2\n",
            "              shapur_restaurant       0.00      0.00      0.00         1\n",
            "                      sonargaon       0.00      0.00      0.00         1\n",
            "                 spag_bowl(bow)       0.00      0.00      0.00         1\n",
            "                         subway       0.00      0.00      0.00         2\n",
            "             sultanahmet_bufesi       0.00      0.00      0.00         1\n",
            "        tasty_treats_restaurant       0.00      0.00      0.00         1\n",
            "                          tesco       0.00      0.00      0.00         2\n",
            "                      the_curve       0.00      0.00      0.00         3\n",
            "             the_curve_mile_end       0.00      0.00      0.00         1\n",
            "                       tiantian       0.00      0.00      0.00         1\n",
            "                       vasiniko       0.00      0.00      0.00         2\n",
            "                       wagamama       0.00      0.00      0.00         1\n",
            "                         wasabi       0.00      0.00      0.00         2\n",
            "         ymca_indian_restaurant       0.00      0.00      0.00         1\n",
            "                  yun_gui_chuan       0.00      0.00      0.00         2\n",
            "\n",
            "                       accuracy                           0.68       650\n",
            "                      macro avg       0.01      0.01      0.01       650\n",
            "                   weighted avg       0.51      0.68      0.56       650\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "**Training and Validation Steps:**\n",
        "\n",
        "Training and validating machine learning models involves several steps, including data splitting, model training, and performance assessment. In the context of the provided machine learning pipeline for classifying food items.\n",
        "\n",
        "**Model Performance Assessment:**\n",
        "\n",
        "1. Accuracy\n",
        "\n",
        "2. Classification Report"
      ],
      "metadata": {
        "id": "yw8T4wVdGVjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "We used the MLend_yummy_dataset to create and validate our model."
      ],
      "metadata": {
        "id": "DwHNMUYHHEvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step_8: Testing the model**\n",
        "\n",
        "Here we test our model by providing it with a dish name such as chicken_masala from the Mile End Yummy Dataset and our model will predict wether its a dish prepared at home or restaurant."
      ],
      "metadata": {
        "id": "qTs4v_btCAcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prediction for a new food description\n",
        "new_food_description = [\"chicken_masala\"]\n",
        "new_prediction = pipeline.predict(new_food_description)\n",
        "print(f'Prediction for new data: {new_prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8UtUJyF9xu-",
        "outputId": "b198f59e-40ec-4865-bb01-fc98f11c94f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for new data: ['home']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result\n",
        "\n",
        "Here we tried providing our model with a random dish from the dataset mentioned above and as expected our model made the right prediction by telling that chicken_masala was a dish prepared at home.\n"
      ],
      "metadata": {
        "id": "oM7Uy7T2HTMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "From the above problem and the solution to build the machine learning pipeline to predict wether a dish is prepared at home or at restaurant we can conclude that the pipeline is working properly and is providing us with a 68% accuracy."
      ],
      "metadata": {
        "id": "BtNeIDB8H0q8"
      }
    }
  ]
}